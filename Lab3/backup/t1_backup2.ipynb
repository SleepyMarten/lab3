{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "file_path = 'data\\seeds_dataset_ver2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#making a dataframe from the txt file. \n",
    "#Original seeds data was wrong format so we had to fix it, which gives us seeds_ver2\n",
    "df = pd.read_table(file_path, delimiter=\"\\t\", names=('area', 'perimeter', 'compactness','length_kernel','width_kernel', 'asymmetry_coefficient','length_kernel_groove','wheat_varieties'))\n",
    "\n",
    "norm_df = normalize(df)\n",
    "#check for null and NaN values.\n",
    "print(df['wheat_varieties'].isnull().sum())\n",
    "print(df['wheat_varieties'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             area   perimeter  compactness  length_kernel  width_kernel  \\\n",
      "count  210.000000  210.000000   210.000000     210.000000    210.000000   \n",
      "mean    14.847524   14.559286     0.870999       5.628533      3.258605   \n",
      "std      2.909699    1.305959     0.023629       0.443063      0.377714   \n",
      "min     10.590000   12.410000     0.808100       4.899000      2.630000   \n",
      "25%     12.270000   13.450000     0.856900       5.262250      2.944000   \n",
      "50%     14.355000   14.320000     0.873450       5.523500      3.237000   \n",
      "75%     17.305000   15.715000     0.887775       5.979750      3.561750   \n",
      "max     21.180000   17.250000     0.918300       6.675000      4.033000   \n",
      "\n",
      "       asymmetry_coefficient  length_kernel_groove  wheat_varieties  \n",
      "count             210.000000            210.000000       210.000000  \n",
      "mean                3.700201              5.408071         2.000000  \n",
      "std                 1.503557              0.491480         0.818448  \n",
      "min                 0.765100              4.519000         1.000000  \n",
      "25%                 2.561500              5.045000         1.000000  \n",
      "50%                 3.599000              5.223000         2.000000  \n",
      "75%                 4.768750              5.877000         3.000000  \n",
      "max                 8.456000              6.550000         3.000000  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k 3 5 7 \n",
    "1 : 75% test = 25%\n",
    "2 : 2/3 test = 1/3\n",
    "3 : 50% test = 50%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for task : a different k with original data.\n",
    "#byt namn p√• det sen\n",
    "def task_a1(k_value, x_train, y_train, x_test,  y_test):\n",
    "    k = k_value\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    print(\"df shape: {}\\ny_train shape: {}\".format(x_train.shape, y_train.shape))\n",
    "    knn.fit(x_train,y_train)\n",
    "\n",
    "    #creating a prediction array for the test set.\n",
    "    y_predict = knn.predict(x_test)\n",
    "\n",
    "    #creating confusion_matrix and printing out the value\n",
    "    confusion_matrix = pd.crosstab(y_test, y_predict, rownames=['Actual'], colnames=['Predicted'])\n",
    "    print(\"\\n\",confusion_matrix)    \n",
    "\n",
    "    # based on the training dataset, our model predicts the following for the test set:\n",
    "    pd.concat([x_test, y_test, pd.Series(y_predict, name='Predicted', index=x_test.index)], \n",
    "          ignore_index=False, axis=1)\n",
    "\n",
    "    #Accuracy value of the test.\n",
    "    print(\"\\nTest set accuracy: {:.2f}\".format(knn.score(x_train, y_train)))\n",
    "    print(f'Using  K = {k}, with original data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_a2(k_value, train_value, test_value):\n",
    "\n",
    "    #Split data into training and test sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(df[['area', 'perimeter','compactness',\n",
    "        'length_kernel','width_kernel','asymmetry_coefficient','length_kernel_groove']],\n",
    "         df['wheat_varieties'], random_state=42, test_size=test_value, train_size= train_value)\n",
    "\n",
    "    # see how data has been split\n",
    "    print(\"X_train shape: {}\\ny_train shape: {}\".format(X_train.shape, y_train.shape))\n",
    "    print(\"X_test shape: {}\\ny_test shape: {}\".format(X_test.shape, Y_test.shape))\n",
    "\n",
    "    #show training data\n",
    "    #print('\\nshow training data\\n',X_train,y_train)\n",
    "    #print trains\n",
    "    #print('\\n',X_train, y_train)\n",
    "\n",
    "    print('\\ntask1 function:')\n",
    "    task_a1(k_value=k_value, x_train=X_train, y_train = Y_train, x_test= X_test, y_test = Y_test)\n",
    "                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (157, 7)\n",
      "y_train shape: (210,)\n",
      "X_test shape: (53, 7)\n",
      "y_test shape: (53,)\n",
      "\n",
      "task1 function:\n",
      "df shape: (157, 7)\n",
      "y_train shape: (157,)\n",
      "\n",
      " Predicted   1   2   3\n",
      "Actual               \n",
      "1          11   0   3\n",
      "2           1  17   0\n",
      "3           1   0  20\n",
      "\n",
      "Test set accuracy: 0.94\n",
      "Using  K = 3, with original data\n"
     ]
    }
   ],
   "source": [
    "task_a2(k_value= 3, train_value= 0.75, test_value= 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df[['area', 'perimeter', 'compactness','length_kernel','width_kernel', 'asymmetry_coefficient','length_kernel_groove']]\n",
    "y_train = df['wheat_varieties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "task_a1() missing 2 required positional arguments: 'x_test' and 'y_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5252/3842983283.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtask_a1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: task_a1() missing 2 required positional arguments: 'x_test' and 'y_test'"
     ]
    }
   ],
   "source": [
    "\n",
    "task_a1(k_value = 3, x_train= x_train, y_train = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (210, 7)\n",
      "y_train shape: (210,)\n",
      "\n",
      " Predicted   1   2   3\n",
      "Actual               \n",
      "1          61   2   7\n",
      "2           5  65   0\n",
      "3           3   0  67\n",
      "\n",
      "Test set accuracy: 0.92\n",
      "Using  K = 5, with original data\n"
     ]
    }
   ],
   "source": [
    "task_a1(k_value = 5, x_train= x_train, y_train = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A k = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (210, 7)\n",
      "y_train shape: (210,)\n",
      "\n",
      " Predicted   1   2   3\n",
      "Actual               \n",
      "1          58   3   9\n",
      "2           3  67   0\n",
      "3           2   0  68\n",
      "\n",
      "Test set accuracy: 0.92\n",
      "Using  K = 7, with original data\n"
     ]
    }
   ],
   "source": [
    "task_a1(k_value = 7)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50f6d2a62cba7b4a04446430090b226dedeaa4907ec121cb2dd7ff424b4ef9c0"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
