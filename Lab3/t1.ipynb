{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "file_path = 'data\\seeds_dataset_ver2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#making a dataframe from the txt file. \n",
    "#Original seeds data was wrong format so we had to fix it, which gives us seeds_ver2\n",
    "df = pd.read_table(file_path, delimiter=\"\\t\", names=('area', 'perimeter', 'compactness','length_kernel','width_kernel', 'asymmetry_coefficient','length_kernel_groove','wheat_varieties'))\n",
    "\n",
    "norm_df = normalize(df)\n",
    "#check for null and NaN values.\n",
    "print(df['wheat_varieties'].isnull().sum())\n",
    "print(df['wheat_varieties'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             area   perimeter  compactness  length_kernel  width_kernel  \\\n",
      "count  210.000000  210.000000   210.000000     210.000000    210.000000   \n",
      "mean    14.847524   14.559286     0.870999       5.628533      3.258605   \n",
      "std      2.909699    1.305959     0.023629       0.443063      0.377714   \n",
      "min     10.590000   12.410000     0.808100       4.899000      2.630000   \n",
      "25%     12.270000   13.450000     0.856900       5.262250      2.944000   \n",
      "50%     14.355000   14.320000     0.873450       5.523500      3.237000   \n",
      "75%     17.305000   15.715000     0.887775       5.979750      3.561750   \n",
      "max     21.180000   17.250000     0.918300       6.675000      4.033000   \n",
      "\n",
      "       asymmetry_coefficient  length_kernel_groove  wheat_varieties  \n",
      "count             210.000000            210.000000       210.000000  \n",
      "mean                3.700201              5.408071         2.000000  \n",
      "std                 1.503557              0.491480         0.818448  \n",
      "min                 0.765100              4.519000         1.000000  \n",
      "25%                 2.561500              5.045000         1.000000  \n",
      "50%                 3.599000              5.223000         2.000000  \n",
      "75%                 4.768750              5.877000         3.000000  \n",
      "max                 8.456000              6.550000         3.000000  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k 3 5 7 \n",
    "1 : 75% test = 25%\n",
    "2 : 2/3 test = 1/3\n",
    "3 : 50% test = 50%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for task : a different k with original data.\n",
    "#byt namn på det sen\n",
    "def task_a1(k_value, x_train, y_train, x_test,  y_test):\n",
    "    k = k_value\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    print(\"df shape: {}\\ny_train shape: {}\".format(x_train.shape, y_train.shape))\n",
    "    knn.fit(x_train,y_train)\n",
    "\n",
    "    #creating a prediction array for the test set.\n",
    "    y_predict = knn.predict(x_test)\n",
    "\n",
    "    #creating confusion_matrix and printing out the value\n",
    "    confusion_matrix = pd.crosstab(y_test, y_predict, rownames=['Actual'], colnames=['Predicted'])\n",
    "    print(\"\\nCONFUSION MATRIX:\\n\",confusion_matrix)    \n",
    "\n",
    "    # based on the training dataset, our model predicts the following for the test set:\n",
    "    pd.concat([x_test, y_test, pd.Series(y_predict, name='Predicted', index=x_test.index)], \n",
    "          ignore_index=False, axis=1)\n",
    "\n",
    "    #Accuracy value of the test.\n",
    "    print(\"\\nACCURACY: {:.2f}\".format(knn.score(x_train, y_train)))\n",
    "    print(f'Using  K = {k}, with original data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_a2(k_value, train_value, test_value, use_data):\n",
    "\n",
    "    #Split data into training and test sets\n",
    "    #Tried with random state 42, but that makes the differnce small\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(use_data[['area', 'perimeter','compactness',\n",
    "        'length_kernel','width_kernel','asymmetry_coefficient','length_kernel_groove']],\n",
    "         use_data['wheat_varieties'], random_state=100, test_size=test_value, train_size= train_value)\n",
    "\n",
    "    # see how data has been split\n",
    "    print(\"X_train shape: {}\\ny_train shape: {}\".format(X_train.shape, Y_train.shape))\n",
    "    print(\"X_test shape: {}\\ny_test shape: {}\".format(X_test.shape, Y_test.shape))\n",
    "\n",
    "    #show training data\n",
    "    #print('\\nshow training data\\n',X_train,y_train)\n",
    "    #print trains\n",
    "    #print('\\n',X_train, y_train)\n",
    "\n",
    "    print('\\ntask1 function:')\n",
    "    task_a1(k_value=k_value, x_train=X_train, y_train = Y_train, x_test= X_test, y_test = Y_test)\n",
    "                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train=⅔ , test=⅓"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train=⅔ , test=⅓"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task a: Original Data\n",
    "## train=75%, test=25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train=75%, test=25%\n",
    "\n",
    "## K = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (157, 7)\n",
      "y_train shape: (157,)\n",
      "X_test shape: (53, 7)\n",
      "y_test shape: (53,)\n",
      "\n",
      "task1 function:\n",
      "df shape: (157, 7)\n",
      "y_train shape: (157,)\n",
      "\n",
      "CONFUSION MATRIX:\n",
      " Predicted   1   2   3\n",
      "Actual               \n",
      "1          10   1   1\n",
      "2           1  17   0\n",
      "3           0   0  23\n",
      "\n",
      "ACCURACY: 0.96\n",
      "Using  K = 3, with original data\n"
     ]
    }
   ],
   "source": [
    "task_a2(k_value= 3, train_value= 0.75, test_value= 0.25, use_data= original_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (157, 7)\n",
      "y_train shape: (157,)\n",
      "X_test shape: (53, 7)\n",
      "y_test shape: (53,)\n",
      "\n",
      "task1 function:\n",
      "df shape: (157, 7)\n",
      "y_train shape: (157,)\n",
      "\n",
      "CONFUSION MATRIX:\n",
      " Predicted   1   2   3\n",
      "Actual               \n",
      "1          11   0   1\n",
      "2           1  17   0\n",
      "3           0   0  23\n",
      "\n",
      "ACCURACY: 0.92\n",
      "Using  K = 5, with original data\n"
     ]
    }
   ],
   "source": [
    "task_a2(k_value= 5, train_value= 0.75, test_value= 0.25, use_data= original_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (157, 7)\n",
      "y_train shape: (157,)\n",
      "X_test shape: (53, 7)\n",
      "y_test shape: (53,)\n",
      "\n",
      "task1 function:\n",
      "df shape: (157, 7)\n",
      "y_train shape: (157,)\n",
      "\n",
      "CONFUSION MATRIX:\n",
      " Predicted   1   2   3\n",
      "Actual               \n",
      "1          12   0   0\n",
      "2           0  18   0\n",
      "3           1   0  22\n",
      "\n",
      "ACCURACY: 0.90\n",
      "Using  K = 7, with original data\n"
     ]
    }
   ],
   "source": [
    "task_a2(k_value= 7, train_value= 0.75, test_value= 0.25, use_data= original_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train=⅔ , test=⅓"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (138, 7)\n",
      "y_train shape: (138,)\n",
      "X_test shape: (70, 7)\n",
      "y_test shape: (70,)\n",
      "\n",
      "task1 function:\n",
      "df shape: (138, 7)\n",
      "y_train shape: (138,)\n",
      "\n",
      "CONFUSION MATRIX:\n",
      " Predicted   1   2   3\n",
      "Actual               \n",
      "1          14   1   3\n",
      "2           1  23   0\n",
      "3           0   0  28\n",
      "\n",
      "ACCURACY: 0.96\n",
      "Using  K = 3, with original data\n"
     ]
    }
   ],
   "source": [
    "task_a2(k_value= 3, train_value= 0.66, test_value= 0.33, use_data= original_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (138, 7)\n",
      "y_train shape: (138,)\n",
      "X_test shape: (70, 7)\n",
      "y_test shape: (70,)\n",
      "\n",
      "task1 function:\n",
      "df shape: (138, 7)\n",
      "y_train shape: (138,)\n",
      "\n",
      "CONFUSION MATRIX:\n",
      " Predicted   1   2   3\n",
      "Actual               \n",
      "1          16   0   2\n",
      "2           1  23   0\n",
      "3           0   0  28\n",
      "\n",
      "ACCURACY: 0.90\n",
      "Using  K = 5, with original data\n"
     ]
    }
   ],
   "source": [
    "task_a2(k_value= 5, train_value= 0.66, test_value= 0.33, use_data= original_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (138, 7)\n",
      "y_train shape: (138,)\n",
      "X_test shape: (70, 7)\n",
      "y_test shape: (70,)\n",
      "\n",
      "task1 function:\n",
      "df shape: (138, 7)\n",
      "y_train shape: (138,)\n",
      "\n",
      "CONFUSION MATRIX:\n",
      " Predicted   1   2   3\n",
      "Actual               \n",
      "1          16   0   2\n",
      "2           0  24   0\n",
      "3           1   0  27\n",
      "\n",
      "ACCURACY: 0.88\n",
      "Using  K = 7, with original data\n"
     ]
    }
   ],
   "source": [
    "task_a2(k_value= 7, train_value= 0.66, test_value= 0.33, use_data= original_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train=50%, test=50%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (105, 7)\n",
      "y_train shape: (105,)\n",
      "X_test shape: (105, 7)\n",
      "y_test shape: (105,)\n",
      "\n",
      "task1 function:\n",
      "df shape: (105, 7)\n",
      "y_train shape: (105,)\n",
      "\n",
      "CONFUSION MATRIX:\n",
      " Predicted   1   2   3\n",
      "Actual               \n",
      "1          21   3   4\n",
      "2           0  35   0\n",
      "3           1   0  41\n",
      "\n",
      "ACCURACY: 0.95\n",
      "Using  K = 3, with original data\n"
     ]
    }
   ],
   "source": [
    "task_a2(k_value= 3, train_value= 0.5, test_value= 0.5, use_data= original_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (105, 7)\n",
      "y_train shape: (105,)\n",
      "X_test shape: (105, 7)\n",
      "y_test shape: (105,)\n",
      "\n",
      "task1 function:\n",
      "df shape: (105, 7)\n",
      "y_train shape: (105,)\n",
      "\n",
      "CONFUSION MATRIX:\n",
      " Predicted   1   2   3\n",
      "Actual               \n",
      "1          23   2   3\n",
      "2           1  34   0\n",
      "3           1   0  41\n",
      "\n",
      "ACCURACY: 0.88\n",
      "Using  K = 5, with original data\n"
     ]
    }
   ],
   "source": [
    "task_a2(k_value= 5, train_value= 0.5, test_value= 0.5, use_data= original_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (105, 7)\n",
      "y_train shape: (105,)\n",
      "X_test shape: (105, 7)\n",
      "y_test shape: (105,)\n",
      "\n",
      "task1 function:\n",
      "df shape: (105, 7)\n",
      "y_train shape: (105,)\n",
      "\n",
      "CONFUSION MATRIX:\n",
      " Predicted   1   2   3\n",
      "Actual               \n",
      "1          23   2   3\n",
      "2           0  35   0\n",
      "3           1   0  41\n",
      "\n",
      "ACCURACY: 0.88\n",
      "Using  K = 7, with original data\n"
     ]
    }
   ],
   "source": [
    "task_a2(k_value= 7, train_value= 0.5, test_value= 0.5, use_data= original_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task a: Normalized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6    7\n",
      "0    0.440982  0.502066  0.570780  0.486486  0.486101  0.189302  0.345150  0.0\n",
      "1    0.405099  0.446281  0.662432  0.368806  0.501069  0.032883  0.215165  0.0\n",
      "2    0.349386  0.347107  0.879310  0.220721  0.503920  0.251453  0.150665  0.0\n",
      "3    0.306893  0.316116  0.793103  0.239302  0.533856  0.194243  0.140817  0.0\n",
      "4    0.524079  0.533058  0.864791  0.427365  0.664291  0.076701  0.322994  0.0\n",
      "..        ...       ...       ...       ...       ...       ...       ...  ...\n",
      "205  0.151086  0.163223  0.637024  0.134009  0.250178  0.372635  0.172821  1.0\n",
      "206  0.060434  0.097107  0.390200  0.135698  0.117605  0.462872  0.238306  1.0\n",
      "207  0.246459  0.258264  0.727768  0.189752  0.429081  0.981667  0.264402  1.0\n",
      "208  0.118036  0.165289  0.399274  0.155405  0.146828  0.368344  0.258493  1.0\n",
      "209  0.161473  0.192149  0.547187  0.193694  0.245189  0.633463  0.267848  1.0\n",
      "\n",
      "[210 rows x 8 columns]\n",
      "0      0.0\n",
      "1      0.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "      ... \n",
      "205    1.0\n",
      "206    1.0\n",
      "207    1.0\n",
      "208    1.0\n",
      "209    1.0\n",
      "Name: 7, Length: 210, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/26414913/normalize-columns-of-pandas-data-frame\n",
    "from sklearn import preprocessing\n",
    "x = df.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "norm_df = pd.DataFrame(x_scaled)\n",
    "print(norm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for task : a different k with original data.\n",
    "#byt namn på det sen\n",
    "def task_a1_norm(k_value, x_train, y_train, x_test,  y_test):\n",
    "    k = k_value\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    print(\"df shape: {}\\ny_train shape: {}\".format(x_train.shape, y_train.shape))\n",
    "    knn.fit(x_train,y_train)\n",
    "\n",
    "    #creating a prediction array for the test set.\n",
    "    y_predict = knn.predict(x_test)\n",
    "\n",
    "    #creating confusion_matrix and printing out the value\n",
    "    confusion_matrix = pd.crosstab(y_test, y_predict, rownames=['Actual'], colnames=['Predicted'])\n",
    "    print(\"\\nCONFUSION MATRIX:\\n\",confusion_matrix)    \n",
    "\n",
    "    # based on the training dataset, our model predicts the following for the test set:\n",
    "    pd.concat([x_test, y_test, pd.Series(y_predict, name='Predicted', index=x_test.index)], \n",
    "          ignore_index=False, axis=1)\n",
    "\n",
    "    #Accuracy value of the test.\n",
    "    print(\"\\nACCURACY: {:.2f}\".format(knn.score(x_train, y_train)))\n",
    "    print(f'Using  K = {k}, with original data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_a2_norm(k_value, train_value, test_value, use_data):\n",
    "\n",
    "    #Split data into training and test sets\n",
    "    #Tried with random state 42, but that makes the differnce small\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(use_data[['area', 'perimeter','compactness',\n",
    "        'length_kernel','width_kernel','asymmetry_coefficient','length_kernel_groove']],\n",
    "         use_data['wheat_varieties'], random_state=100, test_size=test_value, train_size= train_value)\n",
    "\n",
    "    # see how data has been split\n",
    "    print(\"X_train shape: {}\\ny_train shape: {}\".format(X_train.shape, Y_train.shape))\n",
    "    print(\"X_test shape: {}\\ny_test shape: {}\".format(X_test.shape, Y_test.shape))\n",
    "\n",
    "    #show training data\n",
    "    #print('\\nshow training data\\n',X_train,y_train)\n",
    "    #print trains\n",
    "    #print('\\n',X_train, y_train)\n",
    "\n",
    "    print('\\ntask1 function:')\n",
    "    task_a1(k_value=k_value, x_train=X_train, y_train = Y_train, x_test= X_test, y_test = Y_test)\n",
    "                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train=75%, test=25%\n",
    "## K = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['area', 'perimeter', 'compactness', 'length_kernel', 'width_kernel',\\n       'asymmetry_coefficient', 'length_kernel_groove'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2992/418013747.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtask_a2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_value\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_value\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m0.75\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_value\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_data\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnorm_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2992/1776620341.py\u001b[0m in \u001b[0;36mtask_a2\u001b[1;34m(k_value, train_value, test_value, use_data)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#Split data into training and test sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#Tried with random state 42, but that makes the differnce small\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     X_train, X_test, Y_train, Y_test = train_test_split(use_data[['area', 'perimeter','compactness',\n\u001b[0m\u001b[0;32m      6\u001b[0m         'length_kernel','width_kernel','asymmetry_coefficient','length_kernel_groove']],\n\u001b[0;32m      7\u001b[0m          use_data['wheat_varieties'], random_state=100, test_size=test_value, train_size= train_value)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3462\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3464\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3466\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis)\u001b[0m\n\u001b[0;32m   1372\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['area', 'perimeter', 'compactness', 'length_kernel', 'width_kernel',\\n       'asymmetry_coefficient', 'length_kernel_groove'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "task_a2_norm(k_value= 3, train_value= 0.75, test_value= 0.25, use_data= norm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_a2(k_value= 5, train_value= 0.75, test_value= 0.25, use_data= norm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_a2(k_value= 7, train_value= 0.75, test_value= 0.25, use_data= norm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train=⅔ , test=⅓\n",
    "## K = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_a2(k_value= 3, train_value= 0.66, test_value= 0.33, use_data= norm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_a2(k_value= 5, train_value= 0.66, test_value= 0.33, use_data= norm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_a2(k_value= 7, train_value= 0.66, test_value= 0.33, use_data= norm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train=50%, test=50%\n",
    "## K = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_a2(k_value= 3, train_value= 0.5, test_value= 0.5, use_data= norm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_a2(k_value= 5, train_value= 0.5, test_value= 0.5, use_data= norm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_a2(k_value= 7, train_value= 0.5, test_value= 0.5, use_data= norm_df)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50f6d2a62cba7b4a04446430090b226dedeaa4907ec121cb2dd7ff424b4ef9c0"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
